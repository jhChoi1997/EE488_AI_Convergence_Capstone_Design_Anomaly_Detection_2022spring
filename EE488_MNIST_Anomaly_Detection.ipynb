{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE488_MNIST_Anomaly_Detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNayHb8RJyKCwweLzVaRWZ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhChoi1997/EE488_AI_Convergence_Capstone_Design_Anomaly_Detection_2022spring/blob/main/EE488_MNIST_Anomaly_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qx0wd0wRJ8zF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlCEbzhEKCLA",
        "outputId": "143b7e16-6aab-4d6c-c323-e1d90b2af9a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LATENT_DIM = 32\n",
        "EPOCHS = 100\n",
        "BATCH = 32\n",
        "ANOMALY_NUM = 9"
      ],
      "metadata": {
        "id": "YlvTt_YSJ-Vm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = datasets.MNIST(root='MNIST_data/', train=True, transform=ToTensor(), download=True)\n",
        "mnist_test = datasets.MNIST(root='MNIST_data/', train=False, transform=ToTensor(), download=True)\n",
        "\n",
        "train_normal = [mnist_train[i][0].numpy() for i, v in enumerate(mnist_train) if v[1] != ANOMALY_NUM]\n",
        "\n",
        "train_dataset = train_normal[:-int(len(train_normal) / 10)]\n",
        "val_dataset = train_normal[-int(len(train_normal) / 10):]\n",
        "\n",
        "train_dataset = torch.Tensor(train_dataset)\n",
        "val_dataset = torch.Tensor(val_dataset)\n",
        "\n",
        "test_x = torch.tensor([v[0].numpy() for v in mnist_test])\n",
        "test_y = torch.tensor([0 if v[1] != ANOMALY_NUM else 1 for v in mnist_test])\n",
        "test_dataset = TensorDataset(test_x, test_y)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "hGifb5nZJ_Hg",
        "outputId": "31464ef1-81fd-4f76-fc1f-f6d9e4fb510e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-992a1bf5951a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_normal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_normal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/warnings.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, message, category, filename, lineno, file, line, source)\u001b[0m\n\u001b[1;32m    413\u001b[0m                         \"line\", \"source\")\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     def __init__(self, message, category, filename, lineno, file=None,\n\u001b[0m\u001b[1;32m    416\u001b[0m                  line=None, source=None):\n\u001b[1;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n = 500\n",
        "# plt.figure(figsize=(n, 4))\n",
        "\n",
        "# for i in range(n):\n",
        "#   input_image = train_normal[i]\n",
        "#   ax = plt.subplot(2, n/2, i + 1)\n",
        "#   plt.imshow(input_image[0])\n",
        "#   plt.gray()\n",
        "#   ax.get_xaxis().set_visible(False)\n",
        "#   ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "HS3wCzhuc0U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BDEwAp8LdYXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, encoding_dim):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.encoding_dim = encoding_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, self.encoding_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.encoding_dim, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.reshape(x.size(0), -1)\n",
        "        out = self.encoder(out)\n",
        "        out = self.decoder(out)\n",
        "        out = out.view(x.size())\n",
        "        return out"
      ],
      "metadata": {
        "id": "BxcIF_KSKAuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvAutoEncoder(nn.Module):\n",
        "    def __init__(self, encoding_dim):\n",
        "        super(ConvAutoEncoder, self).__init__()\n",
        "        self.encoding_dim = encoding_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 2, kernel_size=(3, 3), stride=(2, 2), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(2, 4, kernel_size=(3, 3), stride=(2, 2), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(8, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(4, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(2, 1, kernel_size=(3, 3), padding=(1, 1)),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.encoder(x)\n",
        "        output = output.view(-1, 16, 2, 2)\n",
        "        output = self.decoder(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "WBKY_XoPU5tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = AutoEncoder(LATENT_DIM).to(device)\n",
        "model = ConvAutoEncoder(LATENT_DIM).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "GKbS81WbU-8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "anomaly_score = nn.MSELoss(reduction='none')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "W8-o7nbnKFQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, X in enumerate(dataloader):\n",
        "        X = X.to(device)\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, X)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 300 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "36YK6WGDKGrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, anomaly_score):\n",
        "    model.eval()\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            output = model(X)\n",
        "            score = torch.mean(anomaly_score(X, output), (1, 2, 3))\n",
        "\n",
        "            y_true.extend(y.tolist())\n",
        "            y_pred.extend(score.tolist())\n",
        "\n",
        "    roc_auc = metrics.roc_auc_score(y_true, y_pred)\n",
        "    print(f'Anomaly Score: {roc_auc:>0.3f}')\n"
      ],
      "metadata": {
        "id": "GB6qgJ_5KJKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(EPOCHS):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, anomaly_score)\n"
      ],
      "metadata": {
        "id": "VMrDeedfKKwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 20\n",
        "plt.figure(figsize=(2*n, 4))\n",
        "\n",
        "for i in range(n):\n",
        "  input_image = test_dataset[i][0].to(device)\n",
        "  output_image = model(input_image.unsqueeze(0))\n",
        "\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(input_image[0].cpu())\n",
        "  plt.title('original')\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(output_image[0].squeeze().detach().cpu())\n",
        "  plt.title('reconstructed')\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ozhPM2pOLZJF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}